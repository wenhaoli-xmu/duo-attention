{"model_name": "models/Llama-2-7B-32K-Instruct", "config_name": null, "dataset_name": "datasets/booksum.jsonl.zst", "dataset_format": "multiple_passkey", "split": "train", "lr": 0.02, "num_steps": 2000, "batch_size": 1, "max_length": 32000, "context_length_min": 1000, "context_length_max": 32000, "context_lengths_num_intervals": 50, "depth_ratio_num_intervals": 1000, "num_passkeys": 10, "output_dir": "attn_patterns/Llama-2-7B-32K-Instruct/lr=0.02-reg=0.05-ctx=1000_32000-multi_passkey10", "sink_size": 128, "recent_size": 256, "deploy_sink_size": null, "deploy_recent_size": null, "reg_weight": 0.05, "initial_value": 1.0, "exp_name": "Llama-2-7B-32K-Instruct/lr=0.02-reg=0.05-ctx=1000_32000-multi_passkey10", "enable_pp": false, "enable_tp": false, "disable_wandb": false, "min_needle_depth_ratio": 0.05, "max_needle_depth_ratio": 0.95, "save_steps": 50, "gradient_accumulation_steps": 1, "resume": false, "rope_theta": null, "device": "cuda:0", "streaming_attn_implementation": "blocksparse", "supervision": "distill", "n_samples": null, "task": "default", "attn_load_dir": null, "threshold": 0.5, "sparsity": null, "passkey_length": 32, "context_length": 16384, "generation_length": 256, "stride_length": 256, "prefilling_chunk_size": 4096, "seed": 42}